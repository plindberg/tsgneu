---
title: Språkmodeller och minne
date: 2025-10-03 09:49
type: fragment
lang: sv
---
(Svar på en fråga på Facebook om huruvida ChatGPT minns och vad.)

Det finns flera aspekter här. En är att längden på det som brukar kallas ’kontextfönstret’ är begränsad. Vid en viss längd kommer den bara att kapa av det äldsta. Om något nämndes bara i början av sessionen så ’glömmer’ den det.

En annan mer subtil aspekt är att det som faktiskt har sagts i sessionen påverkar vad modellen fäster sig vid. Har du pratat mycket och tydligt om en sak så kan den ’glömma’ annat som du pratat mindre eller mer vagt om.

Sedan så har ChatGPT något de kallar minne, som helt enkelt är saker som den har tyckt varit anmärkningsvärt och sparat i en lista över saker. De här infogas alltså bara i kontextfönstret, som om du hade upprepat dem varje gång.

Jag tycker den här funktionen är mycket märklig – just för det jag skrev om att modellen fäster sig vid de saker som har sagts. Att blanda in random saker som kanske är irrelevanta saboterar alltså för dig. Jag ser det som en funktion som har poäng för marknadsföring men inte i praktiken.

Senare införde de möjligheten att leta efter saker i tidigare sessioner under rubriken ’minne’ – något som Claude också gjort nyligen. Det här är ett bättre alternativ till minne, eftersom det fungerar så att modellen kan välja att söka efter något specifikt. Då infogas helt enkelt sökresultat från tidigare sessioner i kontexten.

Jag tror att det här med kontext i språkmodeller är nödvändigt att skaffa sig en viss förståelse för. Språkmodeller är både bekanta – vi chattar med något som tycks förstå oss – och främmande – de beter sig samtidigt väldigt märkligt.
